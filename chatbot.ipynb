{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/zachmacke/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "from nltk.tokenize import word_tokenize \n",
    "import gensim\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "nltk.download('punkt')\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data():\n",
    "    \"\"\"\n",
    "    Loads the data and reads it into dataframes. \n",
    "    \n",
    "    Returns:\n",
    "        questions, answers (pandas Dataframe): question and answers in seperate dataframes\n",
    "        \n",
    "    \"\"\"\n",
    "    data0 = pd.read_csv('python_questions0.csv')\n",
    "    data1 = pd.read_csv('python_questions1.csv')\n",
    "    data2 = pd.read_csv('python_questions2.csv')\n",
    "    data3 = pd.read_csv('python_questions3.csv')\n",
    "\n",
    "    data = pd.concat([data0,data1,data2,data3], ignore_index=False)\n",
    "    \n",
    "    questions = data[['question_id','question_title']].drop_duplicates('question_id')\n",
    "    answers = data[['parent_id','answer','answer_score']] \n",
    "    \n",
    "    return (questions,answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions, df_answers = prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_questions(df):\n",
    "    \"\"\"Tokenize, tag, and stem sentences\n",
    "    \n",
    "    Args:\n",
    "        df (pandas Dataframe): pre-tagged dataframe to iterate through\n",
    "    \n",
    "    Returns:\n",
    "        tagged_sents (list): a list of tokenized sentances\n",
    "    \n",
    "    \"\"\"\n",
    "    taged_sents = []\n",
    "\n",
    "    for sent in range(df_questions.shape[0]):\n",
    "\n",
    "        title = df_questions.iloc[sent]['question_title']\n",
    "        q_id = df_questions.iloc[sent]['question_id']\n",
    "\n",
    "        words = [ps.stem(word) for word in nltk.word_tokenize(title.lower())]\n",
    "\n",
    "        documents = gensim.models.doc2vec.TaggedDocument(words, [str(q_id)])\n",
    "\n",
    "        taged_sents.append(documents)\n",
    "        \n",
    "        if sent % 10000 == 0:\n",
    "            print(sent)\n",
    "        \n",
    "    return (taged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_docs = tag_questions(df_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    \"\"\"\n",
    "    Train the model on a certain set of values and save the model for later \n",
    "    \"\"\"\n",
    "    vec_size = 100\n",
    "    alpha = 0.025\n",
    "\n",
    "    print_every_n = 1\n",
    "\n",
    "    model = Doc2Vec(vector_size=vec_size,dm=0, alpha=alpha, min_alpha=alpha, min_count=0, workers = 4)\n",
    "    model.build_vocab(tagged_docs)\n",
    "\n",
    "    for epoch in range(40):\n",
    "\n",
    "        if epoch % print_every_n == 0:       \n",
    "            print('iteration {0}'.format(epoch))\n",
    "\n",
    "        model.train(tagged_docs,\n",
    "                total_examples=len(tagged_docs),\n",
    "                epochs=1)\n",
    "\n",
    "        if model.alpha > 0.001:\n",
    "            model.alpha -= 0.0002\n",
    "            model.min_alpha = model.alpha\n",
    "\n",
    "    model.save('trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load('trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index of our dataframes \n",
    "df_questions_qid_index = df_questions.set_index('question_id') \n",
    "df_answers_parent_index = df_answers.set_index('parent_id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(user_input):\n",
    "    \"\"\"\n",
    "    Finds the most similar vectors to those in our training set\n",
    "    \n",
    "    Args:\n",
    "        user_input (string): the user's question\n",
    "        \n",
    "    Returns\n",
    "        ques[:9] (list splice): the top 9 closest matching questions to the user input\n",
    "    \"\"\"\n",
    "    \n",
    "    ques = [] \n",
    "    s = set()\n",
    "    \n",
    "    for i in range(20):\n",
    "        tokens = user_input.split()\n",
    "        stem_token = [ps.stem(word) for word in tokens]\n",
    "        \n",
    "        new_vector = model.infer_vector(stem_token,steps=4000)\n",
    "        \n",
    "        sims = model.docvecs.most_similar([new_vector])\n",
    "        for i in sims:\n",
    "            if i[0] not in s:\n",
    "                ques.append(((df_questions_qid_index.loc[int(i[0])]['question_title']),i[0],i[1]))\n",
    "                s.add(i[0])\n",
    "                \n",
    "    ques.sort(key=lambda x: x[1])            \n",
    "    \n",
    "    return(ques[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_bot():\n",
    "    \"\"\"\n",
    "    Initialize the chatbot\n",
    "    \"\"\"\n",
    "    while(True):\n",
    "        print(\"\\nPlease input question:\\n\")\n",
    "        question = input()\n",
    "        if question == 'q':\n",
    "            break\n",
    "\n",
    "        answers= find_similar(question)\n",
    "\n",
    "        def get_answer():\n",
    "            \"\"\"\n",
    "            Create the user interface and use the parent id each question to get the corresponding asnwer\n",
    "            \"\"\"\n",
    "            print(\"\\nWhich answer would you like to see?  \") \n",
    "            print('-'*35) \n",
    "\n",
    "            for x in range(len(answers)):\n",
    "                print(str(x + 1) + '. ' + str(answers[x][0]))\n",
    "            print('-'*35) \n",
    "\n",
    "            print(\"Input a number (1-9): \")\n",
    "            chosen_answer = (int(input()) - 1)\n",
    "\n",
    "            print('\\nHere is your answer: ')\n",
    "            print('-'*35) \n",
    "            ans = df_answers[df_answers['parent_id'] == int(answers[chosen_answer][1])]\n",
    "            max_score = ans['answer_score'].idxmax()\n",
    "            tagged_answer = (ans.loc[max_score]['answer'])\n",
    "            clean_answer = BeautifulSoup(tagged_answer).get_text()\n",
    "            print(clean_answer)\n",
    "\n",
    "        get_answer()\n",
    "\n",
    "        while(True):\n",
    "            print(\"Would you list to see the list again? (y/n): \")\n",
    "            y_n = input()\n",
    "            if (y_n == 'y'):\n",
    "                get_answer()\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please input question:\n",
      "\n",
      "list comprehensions in python\n",
      "\n",
      "Which answer would you like to see?  \n",
      "-----------------------------------\n",
      "1. List comprehensions in python\n",
      "2. Cross-list comprehension in Python\n",
      "3. Saving/Loading lists in Python\n",
      "4. List comprehension python\n",
      "5. Python list append\n",
      "6. Capture-and-yield in a list comprehension\n",
      "7. List comprehension with if-condition\n",
      "8. List Comprehension in Python\n",
      "9. List Comprehension Syntax\n",
      "-----------------------------------\n",
      "Input a number (1-9): \n"
     ]
    }
   ],
   "source": [
    "start_bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env]",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
